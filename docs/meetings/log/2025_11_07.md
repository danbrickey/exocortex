# One-on-one meeting with Ram
Had a good one-on-one meeting with Rom. We discussed coming changes to the department that he reviewed with the department staff this week. I discussed the documentation that I prepared to date for both the EDP architecture and for the business logic guides, and he seemed pleased by that. I'm going to sort of premiere the architecture guidance documents as a way to on-board our new architect next week, Brian Senseman. I'm hoping that he's an experienced architect, so I'm hoping that the documentation I have so far will be sufficient to on-board him. I'll try to make it as detailed as possible, and maybe I can give it to him and he can create a notebook LM or project or something out of it so that he can get up to speed quickly. Anyway, have the information ready is very AI-accessible, so worst-case we can drop it into a M365 Copilot Pro notebook and use it for onboarding kind of training. I will supplement that with lots of whiteboard sessions and verbal explanations, but hopefully this gives him the things he needs to get on-boarded quickly, and in the future as I drive this documentation down into more and more detail, hopefully we can do the same thing with new data engineering staff. 
I also, as part of my efforts to explore the AI coaching career path, or at least having that capability of doing some good coaching for AI in a mentoring capacity as an architect, I offered to do a short presentation on advanced prompt engineering techniques. Rom offered to put me on the schedule for the coffee talk next week, for which I'll be there in person. So I'm going to whip up a little slide deck and presentation to go over things like self-correcting prompts and meta-prompting (like using prompts to improve prompts) and some of those specific techniques that really elevate your prompts. Not super complicated but sort of advanced things that I'm kind of discovering on blogs and YouTube videos and so on out there as that people are using to make their prompts better. 

# Write-up for Ram NOTES:
Ram wants a write-up on a few things:
 - environment hardening process status and progress.
 - A summary of my experience working with the Hakoda contractors. 
 - The progress on the documentation process that I've been working on as part of my code refactoring and to support the data governance efforts with establishing business owned data councils to ratify and maintain business rules. When we refactor code, we are going to produce a logic guide document that describes what the code does in natural language terms with reference material for engineers and analysts as well. Then we're going to hand that over to Data Governance who will ratify it with the business data council members. Once they have agreed that this is what they want, that information will be put into Elation and documented there.
The part of the process that we don't have worked out yet, but that will be important in coming months, is I would like to be able to extract that information that has been produced by the business back out of Elation and use it to evaluate our data engineering code. That's a little bit of a next level thing, but I think it's doable, and it would be really useful to have these natural language documents to use to do an AI evaluation of our code changes. 


I also want to include in the write up On The environment hardening process:
- The move from Rising Sun to North Star
- Hydrating the dev and test environments with data
- Resolving all test and model execution failures that came with it
There are kind of three broad categories to this work:
    1. Our repository was mistakenly deleted because suspected PHI being in the code. It was actually test case data that was in our project for member testing, but in the PHI scans defense it did look exactly like member records. It was just all fake. So that happened which meant that all of our work-in-progress branches were gone. We only got the develop branch back, so we had to create a test and main branches out of the develop branch which included a lot of things that weren't really ready for prime time yet. 
    2. As a result, we've had lots of failures in the models and dependencies that were invalid and things like that - the type of things that you see in a dev environment that get resolved before they're released are now in all of our environments.Working through those has been a really good activity for our codebase, and we've cleaned up a lot of things, but it was time-consuming. 
    3. The third complicating factor is not really something that we anticipated, although it's part of our normal process, which is deprecations to software and engineering functionality in dbt. Recently, we are starting to see dbt's rate of change on their software offering begin to increase, which is a really good thing. I'm assuming it's because they are using AI coding assistance behind the scenes to develop new features and so on. They have a lot of great features coming in the coming months, and they're trying to deprecate old behavior to get ready for that. Anyway, that has complicated things because we've been trying to fix those deprecation warnings because we have a limited time to get them fixed before they become failures. 
    Because of those three complicating factors, it has taken us a couple of weeks longer to get our environments stabilized than we anticipated. However, I feel really good about the work that the engineers have done on this. And I feel good about our repository and some of our working methods going forward. So it's overall been a healthy thing, just more time-consuming than we anticipated.  

The thoughts I have on working with Hakoda are these:
- They've been a fantastic business partner
- The people that they have brought in to help us with things have been very skilled
- However, our impression when Hakoda came on board was that they were bringing finished products or more or less finished products that could be customized to the table with them, and then we were going to work with them on customizing them to work the way we want them to. That's not exactly what happened or we had a misunderstanding on what that was going to be like. So they showed up with a lot of expertise and some prior work and experience dealing with healthcare providers or payers, and they're very good at it. However, they didn't come with finished software or already written code, except in a few cases where they could leverage code they had written in the past for other clients. Other than that, it has been a custom build of these frameworks and playbooks, and that has been a good experience, just a different experience than what we expected. 
- Because of this misconception, I think there has been some negative vibes about our engagement with Hakoda. However, my experience working with the Hakoda folks, Emily and Odell in particular, as well as Lokendra and Shweta (the offshore engineers), is that they are highly competent. They are very good with communication and they are hard-working and very skilled with a lot of deep expertise in things that we need to do. So their help has been invaluable in that sense. 
Overall, it's been for me a very positive experience. I've learned a lot from working with them, and they have accomplished a lot and made the difference in getting things done on time and in a well-architected fashion. Anyway, regardless of our expectations vs reality kind of questions, I have really enjoyed working with the COTA. I think they bring a lot of value to the table. Certainly, far better than any previous business partner we've had in this space of hiring contractors to help with our data engineering work.
- As a result, we have a much more stable environment. It's very secure and well-architected. The RBAC model has been gone over and seems to be working pretty smoothly as we hardened our environments and spun up new environments. The access issues that we've seen in the past were far, far less than we have in the past. That process of sorting out all the permissions has taken weeks or months, and this was basically working the first time we touched it as engineers, which is fantastic. We had just a few tweaks to the permissions and the way they interacted. Those tweaks were done very quickly, and so, in general, the architecture and admin process of creating these new environments hasn't slowed down the engineering part, which has been fantastic. 

# Prompt engineering presentation notes. 
This is a short format slide deck to present the techniques described in "Advanced AI Prompting: A Corporate Training Manual" and "A Beginner's Guide to Advanced Prompting Techniques". I want to create a 6-10 minute video presentation briefly introducing each technique with an example. I want to cover all ten techniques. As well as the overarching principles the SMRPS acronym stands for. Provide a slide with an overview, positive and upbeat through the whole presentation, but not overstating anything. Please do two slides per concept or per technique, and one slide per category. The category slides should briefly describe the thing we are trying to do. The two slides for each technique should first describe the technique in natural language, for the first slide, for the second slide, present a very simple example, for instance on adversarial prompting with a decision analysis prompt you could use the personas of a CFO who's focused on budget and capital expenditure aspects of a decision, the CISO who's focused on security and compliance aspects of an implementation, and a data engineering manager who is focused on the practical bits of getting this new tool to work. The detailed write-up I will include as supplemental material so that I don't take too long on the presentation. So keep the slides light. The job of the slides is to help people understand the basic idea and get them excited about using the technique in their prompt engineering. The supporting documentation: I'll have a user guide and a quick reference guide that I will post along with this slide deck to our company's Confluence page, so that people can go there for more information and examples. I want the slide deck, the presentation, to focus on the potential of these prompts and good natural language conceptual descriptions of each technique. Finally, at the end of the presentation, I want a summary slide. I want to emphasize the fact that this is not a comprehensive list of techniques, just a list of techniques that I know are useful, but there is plenty of room for discovering new ways of creating prompts and using AI to make your prompts better and more solid to give you the results you need. 

# EDP Team 1 Office Hours. 
Demo documentation created by our code refactoring process that I've gotten working. I think Ram will be happy to see that even if it's on a smaller scale than the effort we wanted to do. 

# DBT error work party session 3 
I met with Sumedh, Brad, and Carl again to discuss the member consecutive coverage issue. I've made progress on fixing the root cause in the temporal merge process. I've incorporated the changes into the dbt model and they are now testing them to ensure they resolve the issue.