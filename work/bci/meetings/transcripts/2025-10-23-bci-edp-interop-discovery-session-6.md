TranscriptOctober 23, 2025, 3:02PMLorraine Maldonado started transcriptionLorraine Maldonado   0:03Then.Satish, you ready?Sathish Dhanasekar   0:14Yep, give me one second. I'm just bringing up the sheet.Lorraine Maldonado   0:17No worries. Thank you.Sathish Dhanasekar   0:34OK.Brian.Hello, hi everyone. So I think we covered most of the sources pretty pretty much in detail and have enough information. The specific sources we did discuss about this one again want to talk about like how?Specific questions on certain sources about. I know we talked about last 10 like we talked about this particular set of episodes, parallel intelligence and advance made.I know we did already interest those source like the last item we wanted to discuss was today we are interesting for condition and suspect code. Do we think any other data set that we would be ingesting?And that question is the.+12*******42   1:51We had a we had an outstanding question about Salesforce as a source.Sathish Dhanasekar   2:00Yes to.+12*******42   2:01From a one or two sessions ago and I checked with her.Sathish Dhanasekar   2:04Yeah, that we we want to know how how are we ingesting the data. So like say this is mostly our what we discussed in the last session versus is mostly about the outreach programs and how do we, how we.Enroll those outreach programs. That's the information we had, but what we remained was.+12*******42   2:27Yeah, I think that there's, I think there are more use cases than that. That's just the one I'm familiar with. But I did check with our program manager and we do need to ingest Salesforce as a complete source, not just selected information.Sathish Dhanasekar   2:32Mhm.OK.Kelly Good Clark   2:44But is that for, but is that for 2025 or is that for 2026? Is the statement of work for sales? That's what I, yeah, that's what cause I know eventually, yeah, we do want all of sales for Salesforce and and Dale's not here. I I might be able to go look at the statement+12*******42   2:51Uh, good question. I didn't. I didn't. OK.OK.OK.OK.Kelly Good Clark   3:03work. I I just think that for like, I think there's two pieces here. This This thing right here, which specifically says group assets and program codes. It seems like it's those tables listed, and and I could be wrong. And again, without Dale being here,+12*******42   3:07Thank you.Kelly Good Clark   3:20But I wasn't sure if all of Salesforce because still for it. Yeah, I I don't know. Yeah.+12*******42   3:202.Kelly Good Clark   3:28I I guess that.+12*******42   3:28Yeah, I'll check with Lindsey and see where it's at on the road map and then I can give you a specific time span.Um, or the timeline that that Lindsey's thinking about it?Kelly Good Clark   3:42Because those other tables.+12*******42   3:42Cool. OK. Sorry. Sorry to interrupt. I just wanted to make sure that we talked about that. What's that, Kelly?Kelly Good Clark   3:49Those other tables that are listed there, those are things that we are going to be sending to them. They're coming from the BCI extension table right now. They're because they're custom pre-transformed tables that I think you said Amit makes those or at least one of them. I don't, I don't know, but we'll be sending them those four tables and there's a fifth I think.that is potentially included in there. Um, but we've got a bucket already with those being the sent over that is specific to what it says, group assets and program. So yeah.+12*******42   4:21Got you.Kelly Good Clark   4:24Yeah, so.I know they're pre-transformed tables, right? They're not, they're they're not directly from Salesforce, but I think people call them Salesforce tables.+12*******42   4:29They're not Salesforce tables. Yeah, correct.Yeah. All right, cool. I'll get a I'll get a timeline for you on Salesforce source.OK.It.Now I know we need to ingest more tables, I just don't know when that's required the rest of the Salesforce data.Sathish Dhanasekar   5:30So.OK.+12*******42   5:37But I do know that we need to consume it as an entire.Source system rather than just parts of it, but I'll I'll I'll get with Lindsey and figure out where it is on the road map so I can so we can talk to the timeline.Sathish Dhanasekar   6:11OK. And Dan, do we know like how we gonna set this? At present we decided it's kind of our social data. Is it gonna be historical or is it? So is it, is it incremental data set? I'm I'm pretty sure it's just mean incremental data set.+12*******42   6:26OK.Should should be, yeah.Sathish Dhanasekar   6:30But are we going to just all this historical as well?+12*******42   6:34Probably. I don't. I don't.I don't know that it's that much data volume, but I can ask that as well.Sathish Dhanasekar   6:44Yeah. So historical meaning since it could be lower volume, but do we need to go beyond it's a go forward based on like like the last few years as well that's.+12*******42   6:49Yes.No, it's history. No, we need history as well, but I don't know what the data volume for history is. I I don't think it's a ton of information. It's mostly metadata about our products and sales teams, but.Sathish Dhanasekar   6:55It's true, OK.That's fine.Yeah.Yeah.So I'm still keeping this source only since it's mostly a program data. OK and do is it a daily initial file or like the what the cadence is going to be?For the Salesforce Trader.+12*******42   7:26Uh, that I.That I do not know. I'll ask that as well. The load cadence and.Sathish Dhanasekar   7:34So we're still.+12*******42   7:38Road map where it supports out on the road map. Anything else we need to know about Salesforce you want to?I don't know if this is gonna be delimited files or not that we'll receive the data in. I know there our Salesforce data is in the cloud, so there might be an easier way than just converting it to files and ingesting it. I'll look into that too.Sathish Dhanasekar   8:03So I'm keeping those still TBD. Um.+12*******42   8:06Yeah.Sathish Dhanasekar   8:09OK.So.Let's go back to this. We have to fill some of them. I'll uh.So I know we discussed about this condition and suspect that we are ingesting as part of this.So these are critical data again.We wanna know understand the data set like is it?Historical data. So I think we would we would consume whatever we already ingested, but.Is it the format and the type? Is it still the same from the last time?Are there any changes or?+12*******42   9:00I'm not familiar with these three data sources. Kelly, are you?Kelly Good Clark   9:06I'm not super familiar with them. Yeah, I'm not super familiar with them. Dale was going to work with Tamara Hess's team. Brett Barton. I reached out to Tamara Hess and Brett Barton and asked them if they could attend and.+12*******42   9:07Episodes.Kelly Good Clark   9:23Rhett told me he was not going to be involved, and that his team would not be involved with this. Umm So I don't know. So they'll need to follow up on that. So that's something you want to get with deal on. As far as I know, there are no changes to what we're already doing.But Dale's going to need to work with Rhett on that and get that information.Lorraine Maldonado   9:44Yeah, I think he he already, I mean he started the ball rolling and I think Robert has picked up for him and trying to confirm whom the correct SMEs are for these and and I know it went to a Josh, was it a Josh Mateel or something, but then he deferred to others and.+12*******42   9:55Hello.No.Lorraine Maldonado   10:04And to my knowledge, Robert Lindsey is trying to track that down this week.Kelly Good Clark   10:09OK. And and Robert Lindsay's a good person to be doing that. He's pretty good at shaking things out. So that's good news too. Yeah. But yeah, that definitely would have been a Josh McFeil thing. He would have no idea that that's not his area. This is going to be somewhere and really in Rep Barton's area and who that is in that area, I don't, I don't know for sure.Lorraine Maldonado   10:13Mm-hmm.Yeah, yeah.You said Brett.Kelly Good Clark   10:29I think it's Ryan George now, theoretically, but yeah, Rhett Barton, so.+12*******42   10:32It's it's Rhett RHETTR as in radar HT.Lorraine Maldonado   10:33Rhett.OK.Kelly Good Clark   10:37Yeah, R. H. Ett. Barton. And then, yeah. And so because that was originally Sean Smith and Sean Smith has been replaced by Ryan. George Ryan. George is right to work with. So yeah, I don't know. We'll see what Robert Lindsey is able to shake out. He's really good atgetting things in alignment though.And I'll work with Robert Lindsey on that too, if you need, because I do have a slight background, but.+12*******42   11:04Yeah.Lorraine Maldonado   11:07OK, yeah, maybe maybe I'll find the the, the e-mail and maybe just if you're not already on it, maybe I'll just add you to it, Kelly, and who knows? OK.Kelly Good Clark   11:15Yeah, I was involved. Yeah, I was partially involved in the original part of this, some of this, and working with Sean Smith, who was the original owner of these, and he he's no longer with us. SoLorraine Maldonado   11:23Mm-hmm.Got it. OK. Thank you.+12*******42   11:30OK.Sathish Dhanasekar   11:38So I'm still marking this as TBD now.OK, um.No, we interested this separately. We kind of made a decision. We don't need to do it.And this I know. So the last time we discussed about this edge server was this more of a reporting data that will get submitted to CMSP edge server. I figured this the what I understood from this is more of a.+12*******42   12:11OK.Sathish Dhanasekar   12:13Encounter data that we are submitting to CMS. So this is something we marked as a source only because it's really a reporting data that we are ingesting trying to get into bronze. But what we didn't discuss was the cadence, the file type.+12*******42   12:15OK.Sathish Dhanasekar   12:29Uh.And do we need to ingest historical data as well or it's only go for a data set?Diana Kelly, anybody can provide this information like.Kelly Good Clark   12:44So yes and.I was gonna say, yeah, Ed, again, that's in the, I'm looking at some stuff. So we are replicating it already to you guys. I don't know what you guys have done with it or where that's went. But again, those discussions, I think, I mean, Dan, I don't know. I know Dan, the,+12*******42   13:02OK.Kelly Good Clark   13:07Warehouse folks did stuff with the server at one time. I know I know Kevin McQuillan have worked on it, but.+12*******42   13:08I know the.Yeah, I know the process to submit submit data to the edge server, but I thought this was about consuming data from the edge server.Kelly Good Clark   13:20Oh, I didn't know that was submitting. OK.Sathish Dhanasekar   13:21Oh, it's just so consuming the data from that server.+12*******42   13:27Isn't that what we're talking about? Or the part of the edge server process I'm familiar with is the submission of data to the edge server?Sathish Dhanasekar   13:29Right. Let's see.+12*******42   13:36Which goes to CMS? Um.Kelly Good Clark   13:37This is the opposite. Yeah, so so that was my comment. I didn't realize, I didn't realize. Yeah, I didn't realize that the data warehouse was submitting to Edge. I thought they were consuming from Edge.+12*******42   13:39Yeah, this is this is creating the edge server of the source, yeah.We have one or two tables in the edge server that we pull into HDS for reporting, but it's.We don't really manage the process. They do most of the process on their own. I don't know exactly how they grab the data, probably just through VS code or SSMS running queries and exporting to.Excel spreadsheet or something?So that's a that's again, that's a government programs question, which is probably the case for the next four lines as well.Sathish Dhanasekar   14:30OK.So this is an encounter data BCS server and then maybe they run some checks and audits after that we want to consume the data back from the server OK.+12*******42   14:41Yep. Yeah. So they they do some validation and attesting to the quality, and we estimate the percentage of claims and how many are complete, and so on for the year.Sathish Dhanasekar   14:54OK.+12*******42   14:55So they do a bunch of stuff after we've submitted the data to the edge server. There's a bunch of back and forth between CMS and us on validating and and reporting on the data, so I'm certifying it.And this is not a daily ingestion, I don't think, because the submission process is.Uh, it's somewhere between monthly and quarterly. They give us deadlines for each um submission.And then they start in the fall like usually around this time of year and we submit data until March, maybe the maybe the beginning of April for the prior for this for 2025, we would submit that data starting about now and going into 2020.26, and then there would be a blackout date. But the cadence is not very frequent. It's just like five or six. UmLoads of data during the year followed by a blackout period. So they're very infrequent and that those submissions are about a month or two apart depending on it's kind of it's kind of CMS sets that schedule and we just yeah, CMS sets the schedule and tells us which what dates.Sathish Dhanasekar   16:21So about a month or two.Mhm.+12*******42   16:30We need to submit on which like which incurred dates we need to submit when and then and then we go through the year and it's usually four or five submissions total for the year, but they all happen between September and April.And then there's a like a blackout.Sathish Dhanasekar   16:47So it's it's it's not it's it's so it's it's not kind of a quick schedule, it's just like a demand build.+12*******42   16:51It isn't it? Yeah, it's it's CMS style schedule. They just dictate it and then we follow it and it's a little different every year. But in general it starts in the fall and goes into spring and then it stops for several months while they ingest the data and stuff and then.Start again.Sathish Dhanasekar   17:13OK.+12*******42   17:16OK.Sathish Dhanasekar   17:16Um, so when when you do?+12*******42   17:18That's the submission process, so I'm kind of assuming that the ingestion process would be on a similar cadence.Sathish Dhanasekar   17:27Yeah, so it it it doesn't we we can. So the way I'm thinking then so we probably could depending on in a given month when you would basically send this data to edge server and edge server reproduces it back.In a given timeline, say with a month end or usually on between April to September, usually we get it on a month end or or first of for each month, then we can probably put up a Mm-hmm.+12*******42   17:44Yeah.I.No. Yeah. Yeah, you could do like we could talk about the frequency being like weekly or monthly and then and then when the data shows up, you'll just pick it up and it just may not have data every time, yeah.Sathish Dhanasekar   18:04Yeah, yeah, yeah. That's what I was thinking. Like you could run it weekly or monthly and then when essentially the if the data is not there, the job won't do anything. But if we say it'll just fix it, process it, process the data.+12*******42   18:16Yeah. So we should make the timing the the load cadence should line up with whatever the business process is of consuming that data and I'm not sure what their.Sathish Dhanasekar   18:24Yes. So good. Yeah. So if you if you say the date since we get submit the data comes to our side, if there is a some kind of necessary we need to process and respond within say X amount of date we need to.Load that and say probably we need to have this available in bronze and intent goes to Snowflake share with an X amount of data and then that tries to schedule so.+12*******42   18:41Yeah.OK. Yeah.Sathish Dhanasekar   18:52Right. So I'm, I'm it's safe to assume that we could put this a weekly, then our biweekly.+12*******42   18:53That is good.That makes sense.Sathish Dhanasekar   19:00For now. So if the data is available then we could basically.Pick up.Passes the loads to a bronze and I'm assuming we won't need historical data on this then because it's uh.+12*******42   19:16OK.I don't know if we get. I I can't remember what's actually on the edge server. I think it's just the current year's data. I think there's some history tables in there that give you information about history, but I don't know if it's detail or not.Sathish Dhanasekar   19:28Yeah.+12*******42   19:36Um.Sathish Dhanasekar   19:36So the way I'm thinking this, Dan, say if you're going live by next February, right? Like.+12*******42   19:40Yeah.Sathish Dhanasekar   19:44We may have to reload some of the where they are, and if we do it only between April and September, maybe we'll start from the current year. Yeah, I don't think we would have a story for this. It doesn't make any sense.Thanks.+12*******42   20:04Yeah, some of those questions will have to come from.Either Tamara Hess's team or Ryan George's team.Sathish Dhanasekar   20:11OK. And again, the, yeah, OK.+12*******42   20:12They're the ones who are on the business side and support that process.Sathish Dhanasekar   20:19So I'm assuming the.Oh.So I'm assuming this would Tamil will have to provide the data.Method of transportation. I'm thinking the method of transportation again gonna be object replication or do we directly consume from anywhere else? Those who we would have to wait for Tamron.+12*******42   20:47That's correct, yeah.And probably the same thing on the next four.Sathish Dhanasekar   20:56OK.+12*******42   20:56Uh, CMS related things that's.I think all four of those are CMS, right?Sathish Dhanasekar   21:06I think we may have some clarity on this because we have like.But we don't know, need to know the cadence of this files that we see.So this will also actually.Already interested.So we could probably go back into, but we wouldn't still know the condition pattern.OK.This is the reference status there.Lorraine Maldonado   23:05It's not Tamra anymore, Satish. I think we need to, we need to put there Robert Lindsey to identify this to me. That's that's what we were saying earlier. We're trying to figure out who the right person is.Sathish Dhanasekar   24:12Come home with the pro.Yeah, this we would. Uh.So.Lauren, I think we need to add this as an action item on our end to check follow up with the product. I think we did. I did not go back and check on the checklist with the product. So let's put this as an action item, the reference data set for the product estimation, not ready to release it or we still have to upload from the source.Let's circle back there internally or.OK, yeah, so we need to ingest this from the source. Last time when we spoke, Dan, like we decided that because of the mission data and the custom possibility of custom postage code, we decided that we need to ingest this.Um.But what we didn't discuss was obviously it's it's a one time data load I believe.So is it? Is it a fixed set of data set?+12*******42   26:01One time historical load and then ongoing.Sathish Dhanasekar   26:05I'm sorry, go again.I.OK, OK. I then I think that this is for 20252026 because we are ingesting 2026 vision claims. So I think we can pick it up over there. If it's not a procedure list separately, it doesn't make any sense. Just OK.+12*******42   26:56Yeah, same. Yeah, it's the same source. Yeah, same source.Sathish Dhanasekar   27:03OK, so.Scratch that.+12*******42   27:07But.OK.OK.Hey, Lorraine, while Satisha's doing that, are were you planning on sending the meeting transcripts to BCI?Sathish Dhanasekar   28:44Uh.Lorraine Maldonado   28:46The transcripts are actually for the meetings we've held. They're on the SharePoint, which I think currently the decision initially was that Dale would have access. I'm not sure if Robert has access or not. I can double check.+12*******42   28:48Yeah.OK, I'll pay you there.Lorraine Maldonado   29:15Or or in the interest of time, I don't have any problem with downloading the transcripts and sending them across.+12*******42   29:16Perfect. OK.Lorraine Maldonado   29:24I can do that as well. Is this Dan asking? OK, yeah, Dan, I OK.+12*******42   29:26Yeah, this is Dan. Yeah, I I'd like transcripts so I can, I can make sure I didn't miss anything.Lorraine Maldonado   29:30Sure.All right, I'll, I'll, I can send them to you and that way we don't have a middle man. No problem.Sathish Dhanasekar   29:53But I'm under the chart review clinical data. We did merge this into two. Um.What we didn't decide was whether what data we are supporting from the source.Do we have a right estimate for this call, Dan, for the sources, political data?+12*******42   30:23Kelly, do you know if we have any electronic medical records? I know we have some HL7 data for Quest and LabCorp. Do you have anything else that are clinical kind of records?Kelly Good Clark   30:39I know Dave Johnstone runs something. Actually James Hicks might know more than me and he's on the line. I know James Dave Johnstone runs a pretty big job that needs to be tuned in on EDW2 or or Prod 97.On a regular basis. So I know we have it because I know the job run think is a problem, but James Hicks might know more.+12*******42   30:59OK.+12*******58   31:20It's gonna need to move to ADP.+12*******42   31:21And that and that consumes a file feed that we get.Sathish Dhanasekar   31:29I believe so.+12*******58   31:30Yeah.+12*******42   31:33So it would be that feed that we would pass on to Abacus.Kelly Good Clark   31:38I believe so, yeah. It's that one that Michael Migowski originally, I think, was doing stuff when we first started on WearSky, which is probably why it runs for so long.+12*******42   31:44Oh no.That explains the performance problems.That.OK.Sathish Dhanasekar   32:09OK.+12*******42   32:09So Satish, we need to figure out what the format is for that that incoming file feed that we get for EMR data and then we can give you information about frequency and volume and cadence.Sathish Dhanasekar   32:16No this.Yeah, so I think I'm assuming the road 33 and 34, it's pretty much the same, right? There's all of them are EMR data.+12*******42   32:33Yeah, yeah. Um.Sathish Dhanasekar   32:48Did Johnson.Kelly Good Clark   32:49We.Robert Lindsay, we can't can save is in right the area. So we have to go to Robert Lindsay.+12*******42   32:55Oh, that's right. We have to go through Robert. Yeah, we have to do the box. Sorry, I'm not used to that.Kelly Good Clark   32:59And and that's just for the EMR. That's for line 34 for Varadigm. I can probably help with the Varadigm. Umm+12*******42   33:08IYeah.Sathish Dhanasekar   33:15But.+12*******42   33:15Oh, cool.Yeah.Sathish Dhanasekar   33:24Yeah. So we, I I think the veradigm we discuss about CCD.Kelly Good Clark   33:24So line 34.Sathish Dhanasekar   33:29Yeah.Mhm.Kelly Good Clark   33:44And I I see, I I can probably help with that. I'll have to go look it up, exactly what you need. I guess, what do you need? I mean, you're just, I mean, it's constant. I mean, it's, yeah.Sathish Dhanasekar   33:54So we we know it's it's a CCD HL, CCD is HL7V3 and ADT is HL7V2. We that's the format we probably be sorry that's a probably we'll be getting but what we need is a cadence and confirm that same.Kelly Good Clark   34:05Right.When you say cadence, do you mean like how often we're getting it? Like are the cadence that we've received it?Sathish Dhanasekar   34:20Like.How often we?Yeah, how often we need to interest it, we would get the file.Kelly Good Clark   34:27It's constant, like it's constant. It's like, yeah, it's it's literally, it's like almost, I don't want to say real time per se, but I mean, it's constant. We pull it from BCBSA through an API and it's, I mean, we have it scheduled every three hours, but I think that one is, I'd have to go look exactly, butIt's fairly frequent. It's multiple times a day. Does that work multiple times a day?Sathish Dhanasekar   34:51Oh yeah, yeah, it's it. We can put it every hour earlier server as well. CCD is still we're getting it in.Kelly Good Clark   35:21Oh, yeah, it's it's HL. Well, no, I better not say that. I'll I'll figure it out. OK, so.Sathish Dhanasekar   35:26Yeah, it's mostly that the case, but I just simply don't wanna assume, just get the one confirmation, then you would probably pick it.Kelly Good Clark   35:33Right, right. Yeah. Agreed. Yeah.Sathish Dhanasekar   35:37It's hourly.I'm I'm assuming we did probably.Kelly Good Clark   35:40Because one of them, one of them is XML. So yeah, let me go check.Sathish Dhanasekar   35:45Yeah, I think we do 6ML.Probably. I could be wrong. It's been a while I clicked at the source.OK, so I'm assuming object replication. I'm just filling this out based on what we discuss Kelly. If I if I'm wrong, just call me out.And format and layout is um no it's 207.Is it incremental? So I it's a clinical data.We would probably need, so we would need historical data as well for this. I think that's one of the item also we're going.OK. Oh, it's still she's on the phone now. OK.Kelly Good Clark   37:04Years worth of data. It might at the month be one year at the most, I suspect.Sathish Dhanasekar   38:54Thank you.We'll discuss and I think again this is waiting on the specific.Specific SME for this I believe.Kelly Good Clark   39:12Yeah, I mean the HIC, are we looking at the HICN again? I would put that under Robert Lindsay as well because I don't know who asked for this disappeared. I think this is still just remnants of our initial stuff with you guys, when Sean Smith and his team and the the the RIP stuff.Sathish Dhanasekar   39:17Yes.Kelly Good Clark   39:32I think it's a remnant of that. And if they need it, like are we supplying that to you? And if we are, who's supplying it and what is it used for? You know I I think that just needs to be shaken out and determined. But Robert, Lindsay can figure out who's asking for it and why, what they need.Sathish Dhanasekar   39:54OK.Not applicable. So this one we kind of decided. Thank you Kelly. This one we pretty much you know we said the external provider says we have to load.So I have one question. I know it's the fire data format.That data.Daily.So I'm assuming this fire Jason will be replicated to the object replication as well. That's the assumption I went with. So the last item on this one was done and Kelly was yes, I think Rick was there to give a little bit more rich.Rich Tallon - Contractor   40:57OK, so you're asking about the PB PPD?Sathish Dhanasekar   41:01BCP Yeah, this will.Rich Tallon - Contractor   41:04OK. So is that that's the consumption part, right?Sathish Dhanasekar   41:08Yeah, it's I know we this also should have provided a list from other Blues plan. We would have to ingest because we do have claims coming from those those providers that we have to link to. I think we can insert that since we anyway going to do.A personal identification on the provider. We can ingest it. Just the one last to have like the and this is the for receiving the file. It's going to be a file data set and.Again, it's coming through our S3 buckets, correct?Rich Tallon - Contractor   41:38OK.Yeah, but it's so it's in a. So the raw it's it's in a ND Jason format. So it's each if you're familiar with that. So there's OK.Sathish Dhanasekar   41:42Or.yeahRich Tallon - Contractor   41:57So yeah, you'll just have to parse that from a NDJ son.Set of directories in a S3 bucket.Sathish Dhanasekar   42:07OK.Rich Tallon - Contractor   42:08And uh.If you got some volume estimates recently, those I provided those over to Kelly for our directory. You know what we publish, so it wasn't the.BPD sizing estimates. I'll have to get I'll have to if that if that was the question, I'll have to get you another set of estimates.Kelly Good Clark   42:42a spreadsheet to fill out and it was due today and we sent it back to Dale, but Dale's out. So I don't know, Lorraine, if you're waiting for that. Um It was called specifically, I could, let me let me see what it was called. So if you want, I can maybe send it directlyYou, but it's called.CCI CMS 9115 Discovery questionnaire and we were told it was due today. OK, good. That's not this. OK, good. So the the number that I provided in on that spreadsheet are correct.Sathish Dhanasekar   43:15I think that's for the interrupt interrupt question.+12*******42   43:18Yeah.Sathish Dhanasekar   43:21It's not this.Yeah, I for a second, I have like, what did we discuss about volume on this? OK, I was trying to recollect.Rich Tallon - Contractor   43:24So.OK. Yeah. Yeah. Sorry about that. I just wanted to make sure that I was answering the questions properly. So, all right. So yeah, this is.Sathish Dhanasekar   43:32All right.Rich Tallon - Contractor   43:44Yeah, so it's it's basically a set of buckets and it has a a mix of all the resource types in the buckets. So when I read them, I basically go through and then I figure out what the resource type is and I separate those those resource types.Sathish Dhanasekar   43:53OK.Rich Tallon - Contractor   44:03Types.Sathish Dhanasekar   44:06In the JSON format.Rich Tallon - Contractor   44:09Yep.Because it's from a bulk extract.Sathish Dhanasekar   44:12It's about the extent.Rich Tallon - Contractor   44:14Yep.Sathish Dhanasekar   45:05Mhm.Yeah, we we we we're not adjusting for other blue clients today, but this is something would be a new kind of implementation. We do this for PCP, this particular BCI.Rich Tallon - Contractor   45:29OK.Sathish Dhanasekar   45:37And G, which is we discussed yesterday, it's gonna be DBD for 2026. I think that's what we had. Well, this will be nightly. This all we had mission of.Additional platform details and we will get that and the last thing we discussed was the provider data. So we I'm I'm explicitly leaving this TBD Kelly what you were current extracts. I know we discussed this in the.This is something that you guys are already working on the migration, so we can take a look at that as part of 2026 engagement.When you guys complete the migration.Rich Tallon - Contractor   46:25OK.Sathish Dhanasekar   46:28Makes sense.Kelly Good Clark   46:28Oh, line 40? Line 39, yes, but line 40. Yeah, okay.Sathish Dhanasekar   46:31No, this one. Sorry, 939, sorry.So good with that as a as a decision, OK.Kelly Good Clark   46:42Yes.Yeah, well, and Linda's on the line, so she she's probably a better one to answer that. But yeah, we're going live with the new GEVA version in January. So and I thought that the GEVA was 2026, but I could be wrong.Sathish Dhanasekar   47:03Unless you're saying something.Linsey Smith   47:04What was what was the question for me? The the yes, we we were planning. The road map shows that we were planning to use the existing GEBA extracts that we pull into HDS as the first ingestion.Kelly Good Clark   47:16Yeah.Linsey Smith   47:20And then the second ingestion would be after the Jeeva upgrade to to connect to the APIs to get additional information that's needed.Kelly Good Clark   47:22I can.You guys to get additional.OK, because when Dom was on here, when Dom was on here, he said he was saying we would not be connecting to any G API. Is that right, Dan? I I thought that's what I heard.+12*******42   47:45I don't remember now. He did say something about connecting to Jeeva.Kelly Good Clark   47:47But.Mhm.Sathish Dhanasekar   47:53So.Linsey Smith   48:02They were just my understanding is their views that Jiva has allowed us has has basically set up for us. So that's what I'm expecting. So maybe it's not an extract, but it's essentially.+12*******42   48:14No HDS pulls. HDS pulls the raw tables and recreates the views afterwards.Those had to be reverse engineered. It was a lot of work.Linsey Smith   48:26Hmm.+12*******42   48:47so that the business has data in a format they're used to, but they're not really easy views to store, like in tables and stuff. We'd have to disassemble them.Sathish Dhanasekar   49:18Changes in the existing table structure and schema and secondly we kind of tabled it because also we might have a better mode of integration from last time because I think Dominic was specifying API but then.What web products with AP is not really the best way to go if you're doing a bulk bulk condition and stuff given API's better performance for one one time. So he was going to check with as part of the new implementation, new migration effort.+12*******42   49:40Right.Sathish Dhanasekar   50:20These two points they go is going to take back with the with the migration team to verify we have that make sure we count that kind of integration either a file based or some sort of streaming integration to have a better integration capability.So I just want that to be in when we do with the platform migration. So you guys have to construct, consider that how do we integrate with the EDP solution to ingest the data from Jiva, so either a file or some sort of a stream.+12*******42   50:42OK.OK.That makes sense. Do you wanna go back and talk about Salesforce again? Lindsey's. Lindsey's available now.Sathish Dhanasekar   51:02Oh, yes.+12*******42   51:09Good.Oh yeah. I was just gonna summarize what we talked about before. So we're we're talking about Salesforce as a source. I know there's a handful of custom sort of extracts that we ingest in HDS right now, just three or four of them. So the question was.Sathish Dhanasekar   51:16Sure.+12*******42   51:30Do we need to ingest Salesforce as a as an entire source? And the answer was yes, but the follow-up question is where does that sit on the road map timeline and what? And do you know anything about the cadence or the format that we would get that data in?Does that make sense, Lindsey? OK.OK.OK. Q1 of 2026 was that?Linsey Smith   52:10Right.+12*******42   52:11Does that meet your expectations, Satish? And Lorraine, you were saying you didn't think it was till 2026?Which is true, but it's early 2026.Sathish Dhanasekar   52:28So we so we are ingesting all the sources, so the expected are we?If you're considering all the sources, are we considering all the source pick up at from 2026? Are we going to start ingesting part of it? This the tables that we listed here like say our close program less and eligible resources now this year and then we'll do.+12*******42   52:53No, that.Yeah, exactly. So those those four can come in this year. We have current use cases for a couple of them and then we can ingest Salesforce as a as an entire source in Q1.Linsey Smith   53:12My my struggle with those four is they don't look raw like is that are you ingest? Where are you ingesting those from?+12*******42   53:19They are files that get dropped on the HCS server on Prem, so we can just forward them up to the cloud. But you're right, let's see, those aren't raw. That isn't raw Salesforce data. It's like a.Sathish Dhanasekar   53:20We're not.Linsey Smith   53:58Do a lot of refactoring on the road map, right? We are busy.+12*******42   53:59Do it twice. OK. All right. Yeah, I think that's a good direction. We should just get Josh on the phone and talk to him about it.Um.Well, I think that the main interest is getting all of the Salesforce data in a raw format to go into the bronze layer. We may not need these before we do that, so.The current analytical use cases for the Salesforce data include joining it with the Jeeva data. So we would have, we would have to have both of those forces to do that to serve that use case.Sathish Dhanasekar   54:52Oh yeah.That makes sense. If we don't have the cheaper data anyway, So what is the point of having this data?+12*******42   55:01And so.He's he's his team is the one that sort of owns the Salesforce data and system.Sathish Dhanasekar   55:12OK.+12*******42   55:19I've consumed a little bit of information from it, but not very much so, so we need to get his expertise on it.OK.Metile is his last name, Metile.Sathish Dhanasekar   55:43Come on in the.+12*******42   55:53Yep, like that. That looks right.Linsey Smith   56:16And back on the Jiva concept, we should talk to Stacy unless we have already and I just don't know, but.+12*******42   56:18OK.Lorraine Maldonado   56:41Yeah, we we did have that conversation, but it was I think that's where we concluded with Stacey that with updates coming in January that we we didn't need the Jeeva for 20 for this initial phase one, so.+12*******42   57:03OK.OK.Lorraine Maldonado   57:08Yeah. All right. I'll try to capture an action item here and reach out to Robert and Dale just to let them know. Like, I think we need to revisit the topic here.Linsey Smith   57:09Yep, sounds right.Sathish Dhanasekar   57:30OK.I'm still keeping this TBD for now. So, so former Karen's in addition or do we we are we do we have enough information to go on from the doctor regardless of whether we're going to pick it up this year or not?OK.I'm putting this tool to be the.Giving this to TBD, OK.The final item is on the.Provider web billing and provider web registrations and billing entities.So Rich and Dan, I think this is mostly where your topic were the discussion. So we do decided it's probably a source only data, but the last discussion we didn't have enough time to go over this last time.But do we have any specific use case beyond read loaders and resource only what we needed to use it for? Like the one specific topic we came was do we need this data to decide whether a provider organization operation link and the PCP attribution of that?Do a member.Rich Tallon - Contractor   59:22Mm.Well, I think, I think Dan, you you did express some, I mean there's some values in having the organizational hierarchy that comes from this right in the in the EDP.+12*******42   59:34Yeah, yeah, that'll.Or we need to consume it from some place, some database on Prem if that's where they want to maintain it. So wherever the business wants to maintain the data, then we can consume from there if we need to support that maintenance in.Snowflake with like a streamlined app or something we can do that, but then getting the data to. We also need to get the data to advocates.Sathish Dhanasekar   1:00:16We we.Rich Tallon - Contractor   1:00:21Yeah, so Josh Josh's team also owns this piece and they're doing some some work around this application as well. So you could probably roll in a discussion about this data source with with Josh.+12*******42   1:00:30Oh, cool.No.Rich Tallon - Contractor   1:00:36It.+12*******42   1:00:37Yeah. So the part that I'm unclear of is whether they are gonna maintain the data on Prem and we can consume it through the normal S3 bucket and so on, in which case we can feed it to Abacus as well as the EDP or into the bronze layer of Abacus and then grab it for the EDP. The alternative is.We maintain the data in the in Snowflake and then we give it to Abacus via our Snowshare.Linsey Smith   1:01:05What is this used for? Where did this one come from? Because my EDP road map doesn't have this.+12*******42   1:01:09This is this is provided.This is for a provider. This is a roll up of providers that have multiple facilities in facets. Facets just rolls for practitioner up to facility. So for a hospital system like Saint Luke's, they they actually have like.Rich Tallon - Contractor   1:01:14This is.+12*******42   1:01:32Like a dozen tax IDs and different facilities set up. So this is like a further roll up above facility that represents like larger ownership of the provider organization and that's important because we.Frequently contract with that higher level organization rather than each individual facility that they own.That makes sense. So it's it's fairly simple.Linsey Smith   1:01:59So what do we need it for?+12*******42   1:02:03Well, it's part of the provider dimensionality right now in the EDW 2 and I don't know what are what the other uses would be.Rich Tallon - Contractor   1:02:13So Lindsey, it's also I think of of when you register for the provider portal, this is where the administrator lives and the relationship between that that user and what what organizations they're allowed to administer or.Linsey Smith   1:02:22Yeah.Rich Tallon - Contractor   1:02:32Even view it also it's you know at a low level it controls their security and and authorization, what they can get to and what what they can do. But moreover like if we want to contact, if we want to contact a group.About providers, it should go through the administrative contact and that's where this lives.Right. So if you're right.Linsey Smith   1:02:55Yeah, and so I I know, right? I was a developer on this tool at one point, but my understanding of our direction is that all of this logic is moving to the availability platform. So the idea was.Rich Tallon - Contractor   1:03:09And.Linsey Smith   1:03:11To extract this out as a one time fee to Availity and then it would become the source of truth for that and then we would eventually need to get that from Availity rather than getting it from a source that's about to be retired.Now the timing might not work out on that, but that's that was the direction I was heading. So this is the first time I'm hearing that it's part of our provider dimension. So I guess I need to understand what.+12*******42   1:03:33Well.Linsey Smith   1:03:40What use case would we not be able to deliver on?+12*******42   1:03:42It's just a roll up.Linsey Smith   1:03:46If we waited on this.+12*******42   1:03:46And that would be, yeah, that would be a question for the provider folks on the on the provider reporting so we can get with them.Linsey Smith   1:03:49But.OK, we're gonna meet with him today. Yep. OK.+12*******42   1:03:56We have a form for that, so yeah.Linsey Smith   1:04:01So I'd like to hold on this one. I think Josh Matilda is a good person for us to talk through, especially as we discuss.Abacus and Availity and how this whole thing is going to work, but I did not plan to ingest from this source because it is expected to be retired in 2026.+12*******42   1:04:27That that is information that does not change quickly. So I'm sure there's some interim thing we can do if we need to bridge the gap between our internal process and ability.Linsey Smith   1:04:42Right.And it's probably not hard for us to ingest it, right? It's a SQL database. We have people that could help us. Yeah, so if we have to, we'll do it.+12*******42   1:04:49No, it's it's very simple table.Yeah, it's just a table of tax like these and more owners, yeah.Linsey Smith   1:05:00Sounds good.Well, Lorraine, I say we add it to the to the two topics that we discussed with Josh Mattel. Meanwhile, Dan and I'll take the action to discuss the EDP use case for it and see if it's if we're gonna have to go forward with this.Mhm.Lorraine Maldonado   1:05:20Yep. OK.Linsey Smith   1:05:52OK.Sathish Dhanasekar   1:05:55So other than the TBD item?I don't think we have a.All right, I think 1000 this four items we pretty much covered all of it. Still need to.Right. OK, so these are the list of reminding TBD sources we have. Excuse me, Dan and Kelly, I think.This probably requires a specific point of conversation with the stakeholders rather than a full discovery, I think.Rest of them we can go and work out a solution, start working on our solution planning and how we're going to implement. We think covered for at least for 905 services. We have all the necessary details we need to start our solutioning process so.Kelly Good Clark   1:07:10So then we can go and work out.We think come out quite is the night.Sathish Dhanasekar   1:07:25This will these remaining sources will go go back and have a further point of conversation as part of.Kelly Good Clark   1:07:25So this one, this one.Sathish Dhanasekar   1:07:33In the future meetings.+12*******42   1:07:39Agreed. Yeah, we're down to the point where we need specific contacts for more details.Sathish Dhanasekar   1:07:41OK.Contacts. Yeah, Yep, that's where we are.Kelly Good Clark   1:07:46Yeah.Sathish Dhanasekar   1:07:50So and I I think we are done with this. Other than this specific sources, we're done with the rest of the items. We can go and rock it out and then finalize those other sources and unless I I I believe you have some specific item action items you wanted to come back here.Kelly Good Clark   1:07:54I think.And I was.I I believe you.Sathish Dhanasekar   1:08:11But it's the same, Lauren.Lorraine Maldonado   1:08:12I think, I think all of those action items that we have in the in the chart are these open questions that you have here on your list for all of the sources. So what we should probably just reconcile and make sure that any that we had on the register we've closed out in today's discussion and obviously.Kelly Good Clark   1:08:14I think you, I think all of those actually have the chart are the questions that you have here in your list.Lorraine Maldonado   1:08:32There'll be several that are still open that require this specialized these sinks, so we'll we'll continue to get Dale and Robert's help to try to get these BCI SMEs together to discuss.Kelly Good Clark   1:08:32And obviously.get Gail and Robert's help to try toYeah.Sathish Dhanasekar   1:08:51Other than this, I'm kind of. I'm done with this approach, but.Kelly Good Clark   1:08:56I'm done.Sathish Dhanasekar   1:08:59The other item. So Dan, there is a specific item I wanted to bring.Kelly Good Clark   1:09:01Mhm.Sathish Dhanasekar   1:09:07Don't know whether they had a.Regarding the sensitivity tagging.Kelly Good Clark   1:09:11So in the security.Sathish Dhanasekar   1:09:19Yes, this one.So both the turn ready crosswalk and sensitivity tagging. This is was flash ID JSON.Kelly Good Clark   1:09:26So both the test credit card.This is.Sathish Dhanasekar   1:09:42I'm.I know we this is a Jason. Is it streaming or Jason object?Do you damage goals?So the here that the the classification of this one, how we're going to see is it right time like so flat data JSON form where it comes to our object replication on these sources, correct?Kelly Good Clark   1:09:592.1.Correct.Sathish Dhanasekar   1:10:09On the row 3017 about sensitivity, sensitivity field tagging on our columns.+12*******42   1:10:13I.I don't. I don't know. I don't think it's a one time thing. I think it's an ongoing thing.Sathish Dhanasekar   1:10:27Household and likes it.+12*******42   1:10:28Because those those those fields, the fields, the sensitivity on fields can change. Like you can say oh wait, that field should be masked or that field should not be masked and change your mind on the sensitivity, in which case the tags would get changed and then all the downstream processes would need to change the tags.Kelly Good Clark   1:10:31Yeah.Like.+12*******42   1:10:48In Snowflake, we do that with a feature called tag propagation. So I think those tags will be on the data that we share to you.Sathish Dhanasekar   1:10:53Mhm.Kelly Good Clark   1:10:54Um.+12*******42   1:10:59You.Or it'll well, how will we do that for the Abacus data, Lindsey? There's.Sathish Dhanasekar   1:11:04Note.We we applied on the field, say if you.+12*******42   1:11:10We can, we can send them crosswalks for the row access policies, but what about the column access policies? Do we need to enforce that on the other side or not?Kelly Good Clark   1:11:11You put it on the scale.Sathish Dhanasekar   1:11:20To the column.No, we we should right? Because if because VCA users will also have access to the foundational mods from the back list directly, which means we have to apply. Well, we we can apply.Kelly Good Clark   1:11:26OK.Sure, right.+12*******42   1:11:28Good.Kelly Good Clark   1:11:30The big changes will also happen.+12*******42   1:11:38OK.Kelly Good Clark   1:11:39So.Sathish Dhanasekar   1:11:41Column level tagging. That's what we mean, right? So this is a. So if if you're picking up a specific, say this source field has specific fields, we need to flag it as OK, we need to tag this particular column and sensitive field tag then you meant.Kelly Good Clark   1:11:45You mean, right? So this is a free. So if if you pick me up a special like that's OK, we need to track this particular. Umm+12*******42   1:11:48OK.Please.Sathish Dhanasekar   1:11:58The the way I was expecting this particular source file will tell us what field, what columns we need to flag from the bronze level source side. Source side need to be flagged as a sensitive column and when we propagate that value back to say when we when we create a foundational model out of that.Kelly Good Clark   1:12:00The way I was expecting.So slide need to be flagged as the column and when we propagate the value.To create a foundational model. So the highest value give one of to that field. So the field value of mapping to the of the same kinding presidents.Sathish Dhanasekar   1:12:18So the highest value if one of that field, whichever the column of field value we're mapping to the home residential model have the same tagging precedence from the source itself.+12*******42   1:12:34OK.Sathish Dhanasekar   1:12:34So I was assumption this was on based on the column and that's what we get in the file.Kelly Good Clark   1:12:34So I OK this in the column and that's what we get in the file.+12*******42   1:12:38This is you're you're right, this is the column level masking. However, my the way I was picturing that happening was different, but I don't see a problem with sending you the.Kelly Good Clark   1:12:42XP.Sathish Dhanasekar   1:12:44Mhm.+12*******42   1:12:55Masking tags for the.Raw layer so you can apply them to the bronze layer and all the downstream stuff. The way I pictured it happening was that you would send us the foundation mark and we would do the tagging once it hit our our EDP environment, but they maybe that's not sufficient.Kelly Good Clark   1:13:07Yes.+12*******42   1:13:15Do you? Do you know Lindsey?Are are BCI employees gonna access the Abacus data directly or only through the EDP?Linsey Smith   1:13:20I don't.Sathish Dhanasekar   1:13:29Maybe my assumption was wrong down because I so our assumption. OK, the way I thought was we would get the speed to tag a specific column that is a sensitive or not. Then you would get the same when you when you get the foundational mark.On your Snowflake share, you would know which fields tagged as a sensitive tag. You will simply apply a masking on the Snowflake share which is going to ask right?+12*******42   1:13:59Yeah, that makes sense.That totally makes sense. And that means that the data is secure both at Abacus and on our side, which is nice. Yeah. So what we would need to do is share that tagging metadata with you because those tags get applied in.Linsey Smith   1:14:09Which is what we want, yeah.Sathish Dhanasekar   1:14:11Mm-hmm.+12*******42   1:14:18In the in our raw layer, which is kind of our data lake layer. But then we can take those objects and send you the masking the way that those columns get tagged, which then you'll you can apply that to your bronze layer and then.Those tags can can move.Into the foundation marks and so on.Sathish Dhanasekar   1:14:41OK.Linsey Smith   1:14:41And we discussed that approach with Tina earlier and I don't think the approach was to you to to share the Snowflake raw tags, but instead to share it independently for you to apply.+12*******42   1:14:56M.Linsey Smith   1:14:57If we need to circle back with Tina, let's do that. She'd be the best to speak to it.+12*******42   1:15:01Yeah, let's let's figure out exactly how that that handshaking will work so that we both have the right information. Because data governance, these processes to apply those tags after we get the data into EDP, then they then they review it.Linsey Smith   1:15:09Yep.Sathish Dhanasekar   1:15:09Yeah, I I would like to.+12*******42   1:15:19Go through and tag everything. They have a review process for all the tags that have been applied and so on. That all happens in the EDP data lake layer, the raw layer, and then we could extract that metadata and send it back to you through our Snowflake share.So that you could apply the same thing. Anyway, we just need to figure just to make sure that handshaking works for data governance is the is the thing I'm worried about. I don't. I don't want to have to. I don't want them to have. That's a pretty labor intensive process and so I don't want them to have to do it twice.Sathish Dhanasekar   1:15:46Yeah, we we we probably if you would send the sample data then.+12*******42   1:15:55What's that?Sathish Dhanasekar   1:15:57Yeah, sorry, Dan. Like if you could send us a sample data, I would like to solution this with a pointer group like you, probably you and Lindsey are whom or you wanted to drop. Yeah, OK today have a proper solution planner. How what would be like you said, what is the hand checkpoint? Where are we gonna get this tag data?Linsey Smith   1:16:06Tina Day.+12*******42   1:16:09Yep.Sathish Dhanasekar   1:16:15And what levels from when we apply this to the bronze, we apply it in the conditional mark so that you get those data when you when we share those data to the you get with the tag data. So I think this requires a specific data conversation for solutioning.+12*******42   1:16:27Yeah.Yeah, let's have a separate meeting, solutioning meeting with data governance and make sure we come up with something that fits their process.Sathish Dhanasekar   1:16:41Yeah, OK.So on that part we can again go back and decide the reason why I thought it's a one time thing because if we are going to keep increasing the column that in future if there's a possibility we would add more columns to this list and then we have to update it.I'm gonna put TBD. Maybe we can decide this as part of the solution itself. Solution itself then.+12*******42   1:17:59Yeah, sure. I just, I just know we need the ability to change our mind on the tagging.Sathish Dhanasekar   1:18:00You.Yeah, see the the part where I'm little on that chain mind portrait if I this if we decide this column as tagged.For sensitivity one year down the line if we go and remove the tag.How we would apply that and then propagating when the propagation again happens to the snowflake share, is it back propagate for of the field? It says column blue so it should be fine.OK. Yeah, we'll, we'll, we'll, we'll discuss to be discuss no solution part, OK.+12*******42   1:18:41OK, yeah, yeah. Let's talk about the particulars with data governance, because I might, I want to make sure I'm not misrepresenting what they need, what they need to support.Sathish Dhanasekar   1:19:02And the tenant and group ID walk, we didn't specifically discuss about the method mode of transfer and the file format and all those scenario, all those details then.+12*******42   1:19:13Media.Yeah, the crosswalks lock. I think there will actually be three of them, one for member, one for subscriber, and one for group, depending on what identifier you have in the table.And my well, the way I pictured it was this that we would share the we would give you that data through our Snowflake share to you of.The crosswalks and then you could pull them in and apply them.But we should have a we can, we can have that same data governance conversation cover this as well.Sathish Dhanasekar   1:19:56OK.To be so.+12*******42   1:20:02OK.Sathish Dhanasekar   1:20:03The other three set member group and.+12*******42   1:20:07Subscriber.Sathish Dhanasekar   1:20:34Yeah, I don't know.+12*******42   1:20:41Sure.Sathish Dhanasekar   1:21:01OK.So Lauren, I think these two items are a separate detail focus meeting and other along with other action items to get first track. So I'm good for now Lauren.Lorraine Maldonado   1:21:16Was there? I just had one other question and sorry I missed it. Did you close out on the provider directory, the BCBSA order? Yeah, there was still. Did we close up today or?+12*******42   1:21:19OK.Sathish Dhanasekar   1:21:24No, I did not. Yes, we did. We.Lorraine Maldonado   1:21:31I know at one point we captured in action here that we probably needed to have a separate deep dive or something.Sathish Dhanasekar   1:21:34Yeah, we we.So we have to ingest this data, Lauren. That's what we kind of finalized since we are getting a claims and what associated to this provider, we have to ingest it and then.Lorraine Maldonado   1:21:49Mhm.Sathish Dhanasekar   1:21:54As part of a separate directory source and then.Rick, Rich just informed us it's gonna be in Jason format and file format. So we just the source and we do a.Lorraine Maldonado   1:22:06OK.Sathish Dhanasekar   1:22:11So when we're doing and mastering record for this, so all providers, both provider and members, so it should be OK.Lorraine Maldonado   1:22:20OK, right.Rich Tallon - Contractor   1:22:21And if you have any specific question during connector design, we will come back and ask those and and I've already got some. I've got glue jobs that break that apart already so I can share that code with you if you need it.Lorraine Maldonado   1:22:26OK, sounds good.Sathish Dhanasekar   1:22:35That would be wonderful. That would be helpful, yeah.Rich Tallon - Contractor   1:22:44OK.Sathish Dhanasekar   1:22:53Is it single code or the?Rich Tallon - Contractor   1:22:57Uh, no, it's, uh, it's Peisberg.Sathish Dhanasekar   1:23:01Oh.Rich Tallon - Contractor   1:23:10But I mean, it'd be pretty pretty easy to kind of convert it to SQL.Sathish Dhanasekar   1:23:17Yeah, it's not that big deal. Yeah, that would be helpful.But.Yeah, that's all I have, Lauren today.I think the rest step is for us to go and find a clean up, provide a clean up list other than those action items and we start discussing about the next implementer connected design phase and all those things. Yeah and draw our solution.Lorraine Maldonado   1:23:31OK.Yeah.All right. Well, sounds good. I will. I'll gather before end of day today. I'll gather the transcripts that we have to date and I'll share them with you, Kelly, I guess. And Dan, Dale and Robert, I'll make sure that at least you all have those and you can share them.Sathish Dhanasekar   1:23:59Hmm.Lorraine Maldonado   1:24:05How we need.Sathish Dhanasekar   1:24:08One other thing like so.We do need some meeting on the calendar for I think next week would be right right again later after Wednesday or Thursday would be the right time to discuss on those two items solution specific detail meeting on these two items.Lauren, so Dan like.Lorraine Maldonado   1:24:28Which? I'm sorry, which two? The from today's conversation. OK, yes, yes.Sathish Dhanasekar   1:24:30RDM group and tenant crosswalk. Yeah, group and ten ready crosswalk and source will sensitivity tagging. This is probably the question specific point of conversation. Laura, that that's a solution meeting.Lorraine Maldonado   1:24:37Mm-hmm.OK, yeah.Yeah, let's meet in your chat. Actually, if we have time, maybe we can just sync up real quick right now after this and then we'll see. I can make sure I can chat with Lindsey, Robert Lindsey today and make sure we can get the sessions on the calendar.Sathish Dhanasekar   1:24:59Yeah, we I have a remember we I have a meeting scheduled for an hour session after around 1:30. We can have go over those along with the notes and review this.Lorraine Maldonado   1:25:10Sounds great. Thank you.Great. All right. If nothing else for the larger team here, then I guess we will give you back a little bit of time.Sathish Dhanasekar   1:25:21No, thanks, Lindsey. Thanks, Kelly, and thanks, Dan, for all the reports.Daphne Park   1:25:24Thank you.+12*******42   1:25:27Awesome. Thanks guys. See ya.Linsey Smith   1:25:29Good job, all. Thank you. Yeah.Lorraine Maldonado   1:25:30Thanks all. Bye.Kelly Good Clark   1:25:30Yep. Thanks, everybody. Bye.Lorraine Maldonado stopped transcription
