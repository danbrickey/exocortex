# EDP Business Alignment Stretch Goals 
I met with Lindsay Smith and the Data Governance team. We discussed the EDP 24-month roadmap progress, and we started preparing for the next PI, which we're going to finish in an on-site set of meetings next week. We talked about the member and product data council creations. We spent quite a bit of time talking about common definitions. For instance, we've been using the term "provider data model," "provider 360," or "provider marked" sort of interchangeably, and they do have different implications. So we tried to get those definitions straight. The task in front of us prior to the start of NextPI is to get the data councils formed and get the conversation going and get some rough data models in front of them, or at least natural language metrics of things that they want to be able to measure about those domains. First priority is provider, member, and product. We're focusing on those three domains right now. 
# EDP Team 1 Daily Stand-Up
Short meeting. Not too many folks showed up. We just gave our status updates, and it was only a few minutes. 

# EDP Scrum of scrums meeting. 
Discussed where we were on environment hardening and the refactoring of the code for the OneView app and the standing up of the test environment. At this point, test had many thousands of model failures and test failures, both maybe over a thousand but probably 25% of the load was failing due to either model execution errors or test errors. I'm working on that this week and next with the data engineers. 

# Discuss EDP layer functionality for near real-time use cases. 
Jason, Shreya, and I met with Ronga to discuss the near real-time use cases and requirements for dynamic tables. We went through a bunch of the limitations of dynamic tables. One of which is that they won't consider data masking policy logic to be too complex or something, and they don't handle it. This means we can't get the tags to propagate. Ronga is going to look into it with the product team and see where that's at on the roadmap because he thinks that they are working on a solution for that. We didn't get too far on solutioning, but we did go over the scope of the requirements for the dynamic table pipe-based pipeline that we'd like to use for near real-time. We talked through some of the problems that we're running into with that, and Sorong is going to do some research, and we will meet again on Wednesday. 

# Eligibility Flattened Overlapping Date Errors 
Looks like one of the dependencies for the Eligibility Flattened Base Table that we use for Eligibility Extracts is Member Consecutive Coverage Model. It is creating rows, eligibility rows, with overlapping dates, and it is dropping some dates. We need to troubleshoot that. Sumedh's going to take a look at it and see if he can come up with a key and figure out what's going on. 

# EMR clinical dataset. 
Met with Kathy Rexroad and Lindsey Smith. Discussed the particulars of the EMR clinical data that's being adjusted by HDS right now on-prem and talked about what it would take to get it up into the cloud. We're going to take that back to the business and see if this EMR data is something that they want. 

# DBT training with Lakshmi's team part 2 
Continued the DBT training with Lakshmi's team. We went over some of the more advanced topics around testing, documentation, and sources. We also talked about some of the refactoring that we're doing in EDP and how that might apply to their team as they start to refactor some of their code. We had a good discussion around best practices for DBT development and some of the pitfalls to avoid. Ran into an issue that I need to troubleshoot with the `ingest` environment variable. Seems like it's difficult to use that and it doesn't point everything to the right spot. We're going to need that for this type of development, which they are working on the ingestion for at the same time as the rest of the pipeline. 

# Non-meeting time. 
Spend most of the day working on the test environment, pipeline failures, working through what we're causing those and meeting with some of the data engineers on the different teams to determine what their requirements were for the new test environment. 